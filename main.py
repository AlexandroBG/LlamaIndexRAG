from config import configure_gemini
from loader import load_documents
from indexer import build_index
from query_engine import create_query_engine, ask_question

def main():
    print("ğŸš€ Iniciando RAG con Gemini GRATUITO + LlamaIndex")
    print("=" * 50)

    # Configurar Gemini (solo tier gratuito)
    model = configure_gemini()

    # Cargar documentos (descarga automÃ¡tica del PDF si no existe)
    print("\nğŸ“„ Cargando documentos...")
    documents = load_documents("data")
    print(f"âœ… Documentos cargados: {len(documents)}")

    # Construir Ã­ndice con embeddings HuggingFace (gratis y local)
    print("\nğŸ” Construyendo Ã­ndice vectorial...")
    index = build_index(documents)
    print("âœ… Ãndice construido")

    # Crear motor de consultas
    print("\nâš™ï¸ Configurando motor de consultas...")
    query_engine = create_query_engine(index)
    print("âœ… Motor de consultas listo")

    # Consultas de ejemplo
    questions = [
        "What is LangChain?",
        "What are the main components mentioned in the document?",
        "Summarize the key points of this paper"
    ]

    print("\n" + "=" * 50)
    print("ğŸ¤– CONSULTAS DE EJEMPLO")
    print("=" * 50)

    for i, question in enumerate(questions, 1):
        print(f"\nğŸ“ Pregunta {i}: {question}")
        print("-" * 40)
        response = ask_question(query_engine, question)
        print(f"ğŸ¤– Respuesta: {response}\n")

        # Pausa entre preguntas para no saturar la API gratuita
        if i < len(questions):
            print("â³ Pausa de 2 segundos...")
            import time
            time.sleep(2)

    print("\n" + "=" * 50)
    print("âœ… Demo completada usando solo recursos GRATUITOS")
    print("ğŸ’¡ Gemini: API gratuita")
    print("ğŸ’¡ Embeddings: HuggingFace local (gratis)")
    print("ğŸ’¡ LlamaIndex: Open source")

if __name__ == "__main__":
    main()
